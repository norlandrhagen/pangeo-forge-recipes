{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a Recipe Locally\n",
    "Welcome to the Pangeo Forge introduction tutorial! This is the 2nd part in a sequence, the flow of which is described {doc}`here </introduction_tutorial/index>`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code from Part 1\n",
    "You'll need the `FilePattern` that was created in Part 1 to work on Part 2.  The Part 1 code is copied here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pangeo_forge_recipes.patterns import ConcatDim, FilePattern\n",
    "\n",
    "dates = pd.date_range('1981-09-01', '2022-02-01', freq='D')\n",
    "\n",
    "URL_FORMAT = (\n",
    "    \"https://www.ncei.noaa.gov/data/sea-surface-temperature-optimum-interpolation/\"\n",
    "    \"v2.1/access/avhrr/{time:%Y%m}/oisst-avhrr-v02r01.{time:%Y%m%d}.nc\"\n",
    ")\n",
    "\n",
    "def make_url(time):\n",
    "    return URL_FORMAT.format(time=time)\n",
    "\n",
    "time_concat_dim = ConcatDim(\"time\", dates, nitems_per_file=1)\n",
    "pattern = FilePattern(make_url, time_concat_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 Outline\n",
    "\n",
    "The main goal of the first two parts of this tutorial are to create and run a **recipe**, the object that defines our data transformation.\n",
    "A recipe is an Apache Beam [Composite Transform](https://beam.apache.org/documentation/programming-guide/#composite-transforms).\n",
    "\n",
    "In part 2 of this tutorial we wil be using the `FilePattern` we defined in Part 1 to create a recipe and use it to create some cloud optimized data on our own computer!\n",
    "\n",
    "The steps to doing this are:\n",
    "1. Prune the FilePattern\n",
    "1. Chain together the necessary beam transforms into a recipe\n",
    "1. Run the recipe as a Beam Pipeline\n",
    "1. Check output data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune the File Pattern\n",
    "\n",
    "\n",
    "Currently our recipe is set up to convert over 3 decades worth of data. That is much more data than we need to run a test (and probably more data than fits on our computer). What we want instead is to run a subset of the data, just to make sure the recipe is working. \n",
    "\n",
    "Pangeo Forge has a built in function for getting a smaller test-appropriate file pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_pruned = pattern.prune()\n",
    "\n",
    "pattern_pruned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Recipe object (Beam Composite Transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "from pangeo_forge_recipes.transforms import OpenURLWithFSSpec, OpenWithXarray, StoreToZarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A place for our data to go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import TemporaryDirectory\n",
    "td = TemporaryDirectory()\n",
    "target_path = td.name + \"/output.zarr\"\n",
    "target_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = (\n",
    "    beam.Create(pattern_pruned.items())\n",
    "    | OpenURLWithFSSpec()\n",
    "    | OpenWithXarray(file_type=pattern_pruned.file_type)\n",
    "    | StoreToZarr(\n",
    "        target=target_path,\n",
    "        combine_dims=pattern.combine_dim_keys,\n",
    "    )\n",
    ")\n",
    "transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with beam.Pipeline() as p:\n",
    "    p | transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check output\n",
    "\n",
    "Now that the process has run we can use `xarray` to inspect the output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oisst_zarr = xr.open_dataset(target_path, engine=\"zarr\")\n",
    "oisst_zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oisst_zarr['sst'].sel(time='1981-09-02').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There it is! Some zarr data that we created during this tutorial! We have converted the netCDF OISST data to zarr and opened it up in xarray. We have a working local recipe.\n",
    "\n",
    "If we wanted to run the recipe on the full dataset (as opposed to the much smaller pruned version), we would just repeat the above steps on recipe rather than recipe_pruned. This would take a long time, but it would work."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "pangeo-forge-recipes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "8472a85c0cbfd90fc84f178c7f47d34e20396f42fa331cce9968659ce876ac9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
